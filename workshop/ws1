from mpl_toolkits.mplot3d.axes3d import Axes3D
from matplotlib import cm
import matplotlib.pyplot as plt
import numpy as np
from sympy import  *
from scipy.optimize import minimize_scalar
import pandas
"""
Question 1.1
"""

"""
fig = plt.figure()
ax = fig.add_subplot(1, 2, 1, projection='3d')
X=np.arange(-10,10,1)
Y=np.arange(-10,10,1)
X, Y = np.meshgrid(X, Y)
Z = (2*X)**2 +(2*Y)**2

surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,
cmap=cm.jet,linewidth=0.01, antialiased=False)
ax.set_zlim3d(0,1000)

ax = fig.add_subplot(1, 2, 2, projection='3d')
X=np.arange(-10,10,1)
Y=np.arange(-10,10,1)
X, Y = np.meshgrid(X, Y)
Z = -(2*X)**2 +(2*Y)**2
surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1,
cmap=cm.jet,linewidth=0.01, antialiased=False)
ax.set_zlim3d(-1000,0)
fig.colorbar(surf, shrink=0.5, aspect=5)
plt.show()
"""



'''
Question 1.3
'''

# def
# x = Symbol('x')
# y = Symbol('y')
# z = (2*x )**2 +(2*y)**2
# dzdx = z.diff(x)
# dzdy = z.diff(y)
# div_z = [dzdx, dzdy]
# dzdxx = dzdx.diff(x)
# dzdxy = dzdx.diff(y)
# dzdyx = dzdy.diff(x)
# dzdyy = dzdy.diff(y)
# div2_z = [[dzdxx, dzdxy],[dzdyx, dzdyy]]
# # div2_z
# print(div_z)
# print(div2_z)
# fig_2 = plt.figure()
# ax_1 = fig_2.add_subplot(1,2,1, projection='3d')
# X=np.arange(-10,10,1)
# Y=np.arange(-10,10,1)
# X,Y = np.meshgrid(X,Y)
# # Z = div_z[0]+div_z[1]
# Z = (2*X)**2 +(2*Y)**2
# surf = ax_1.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet,linewidth=0.01, antialiased=False)
# Z = 8*X
# surf = ax_1.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.Purples,linewidth=0.01, antialiased=False)
# Z = 8*Y
# surf = ax_1.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.Oranges,linewidth=0.01, antialiased=False)
# Z = 8+0*X*Y
# surf = ax_1.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.Oranges,linewidth=0.01, antialiased=False)
#
# ax_1.set_zlim3d(0,1000)
# plt.show()


# ax_2 = fig_2.add_subplot(122, aspect='auto')
# X=np.arange(-10,10,1)
# Y=np.arange(-10,10,1)
# X, Y = np.meshgrid(X, Y)
# Z = -(2*X)**2 -div_z[1]
# surf = ax_2.plot_surface(X, Y, Z, rstride=1, cstride=1,
# cmap=cm.jet,linewidth=0.01, antialiased=False)
# ax.set_zlim3d(-1000,0)
# fig.colorbar(surf, shrink=0.5, aspect=5)


# #Q2.2
# fig_3 = plt.figure()
# ax_2 = fig_3.add_subplot(1,2,1)
# P = np.linspace(0,1,100)
# N=10
#
# S=[N*i*(1-i)**(N-1) for i in P]
# plt.plot(P,S)
#
#
# #Q2.3
# S = Symbol('S')
# P = Symbol('P')
# S=N*P*(1-P )**(N-1)
#
# ds = S.diff(P)
# ax_2 = fig_3.add_subplot(1,2,2)
# k=np.linspace(0,1,100)
# a = ds._args[0]+ds._args[1]
#
# # print(a.subs(P,1))
# ds_fig=[a.subs(P,i) for i in k]
# plt.plot(k, ds_fig)
#
# plt.show()

# def f(x):
#     return -(N*x*(1-x)**(N-1))
#
# res = minimize_scalar(f)
# print(res.x)


# Q2.4.2&3

# next_x_1 = 4 # We start the search at x=6
# gamma = 0.002  # Step size multiplier
# next_x_2 = 3
#
#
# precision = 0.00001  # Desired precision of result
# max_iters = 100000  # Maximum number of iterations
#
# # Derivative function (Q=[[1 0][0 1]], r=1)
# # df_1 = lambda current_x_1 : 2*next_x_1
# # df_2 = lambda current_x_2 : 2*next_x_2
#
# # Derivative function (Q=[[10 0][0 1]], r=10)
# df_1 = lambda current_x_1 : 2*next_x_1
# df_2 = lambda current_x_2 : 2*10e-6*next_x_2
#
# cnt=0
# for i in range(max_iters):
#
#     current_x_1 = next_x_1
#     current_x_2 = next_x_2
#
#     next_x_1 = current_x_1 - gamma * df_1(current_x_1)
#     next_x_2 = current_x_2 - gamma * df_2(current_x_2)
#     step_1 = next_x_1 - current_x_1
#     step_2 = next_x_2 - current_x_2
#     cnt += 1
#     if abs(step_1) <= precision and abs(step_2) <= precision:
#         break
#
#
# print("Minimum at", next_x_1)
# print("Minimum at", next_x_2)
# print(cnt)

# Q2.4.3
next_x1 = 1  # We start the search at x=6
next_x2 = 3
gamma = 0.0002  # Step size
precision = 0.00001  # Desired precision of result
max_iters = 100000  # Maximum number of iterations

# Derivative function
df1 = lambda x1: 4*x1
df2 = lambda x2: 4*x2
count = 0
# for i in range(max_iters):
#     current_x1 = next_x1
#     current_x2 = next_x2
#     next_x1 = current_x1 - gamma * df1(current_x1)
#     next_x2 = current_x2 - gamma * df2(current_x2)
#     step1 = next_x1 - current_x1
#     step2 = next_x2 - current_x1
#     count += 1
#     if abs(step1) <= precision and abs(step2) <= precision:
#         break
#
# print("Minimum at", next_x1, next_x2)
# print(str(count) +" steps")
#
#
# next_x1 = 1  # We start the search at x=6
# next_x2 = 3
# gamma = 0.002  # Step size multiplier
# precision = 0.00001  # Desired precision of result
# max_iters = 100000  # Maximum number of iterations
#
# # Derivative function
# df1 = lambda x1: 4*x1
# df2 = lambda x2: 4*10e-6*x2
# count = 0
# for i in range(max_iters):
#     current_x1 = next_x1
#     current_x2 = next_x2
#     next_x1 = current_x1 - gamma * df1(current_x1)
#     next_x2 = current_x2 - gamma * df2(current_x2)
#     step1 = next_x1 - current_x1
#     step2 = next_x2 - current_x1
#     count += 1
#     if abs(step1) <= precision and abs(step2) <= precision:
#         break
#
# print("Minimum at", next_x1, next_x2)
# print(str(count) +" steps")
#
# # Q2.4.3
# df1 = lambda x1: 4*x1
# df2 = lambda x2: 4*x2
# count = 0
#
#
# for i in range(max_iters):
#
#     current_x1 = next_x1
#     current_x2 = next_x2
#     gamma_auto = 1/(i+1)
#     next_x1 = current_x1 - gamma_auto * df1(current_x1)
#     next_x2 = current_x2 - gamma_auto * df2(current_x2)
#     step1 = next_x1 - current_x1
#     step2 = next_x2 - current_x1
#     count += 1
#     if abs(step1) <= precision and abs(step2) <= precision:
#         break
#
# print("Minimum at", next_x1, next_x2)
# print(str(count) +" steps")

# Q2.4.4
#
# next_x1 = 2 # We start the search at x=6
# next_x2 = 2
# #beta = 0.1
# c1 = 0.3
# precision = 0.00001  # Desired precision of result
# max_iters = 50 # Maximum number of iterations
#
# # Derivative function
# df1 = lambda x1: 2*x1
# df2 = lambda x2: 2*x2
# f = lambda x1, x2: x1**2+x2**2
# x_iters = 0
# alpha_iters = 0
# alpha = 5
#
# def get_alpha(max_iters, alpha, current_x1, current_x2):
# #    df1 = lambda x1: 2*x1
# #    df2 = lambda x2: 2*x2
# #    f = lambda x1, x2: x1**2+x2**2
#    for j in range(100):
#        alpha = 0.95*alpha
#        x1_ = current_x1 - alpha*df1(current_x1)
#        x2_ = current_x2 - alpha*df2(current_x2)
# #        print('alpha1:',alpha)
#
#        if f(x1_, x2_) <= f(current_x1, current_x2) - c1*alpha*(df1(current_x1)**2+df2(current_x2)**2):
# #            print('alpha1:',alpha)
# #            print(alpha_iters)
#            #print('1111')
#            print(alpha)
#            break
#
#    return alpha
#
#
# for i in range(max_iters):
#    x_iters += 1
#    current_x1 = next_x1
#    current_x2 = next_x2
#    alpha = get_alpha(max_iters, alpha, current_x1, current_x2)
#    next_x1 = current_x1 - alpha * df1(current_x1)
#    next_x2 = current_x2 - alpha * df2(current_x2)
# #    print('alpha2:', alpha)
# #    step1 = next_x1 - current_x1
# #    step2 = next_x2 - current_x2
#    dfdx1 = df1(next_x1)
#    dfdx2 = df2(next_x2)
#    if abs(dfdx1) <= precision and abs(dfdx2) <= precision:
# #        print(next_x2)
# #        print(current_x2)
#        break
#
#
# print("Minimum at", next_x1, next_x2)
# print(str(x_iters) +" steps")






# #Q2.4.5
# def f(X,Y):
#     return (2*X)**2+(2*Y)**2
#
# X = np.linspace(-5,5,100)
# Y = np.linspace(-5,5,100)
# X,Y = np.meshgrid(X ,Y)
# plt.contour(X,Y,f(X,Y),20)
#
# X = np.linspace(-5,5,20)
# Y = np.linspace(-5,5,20)
# X,Y = np.meshgrid(X ,Y)
# # u = -8 * X
# # v = -8 * Y
#
# # plt.title('Arrows scale with plot width, not view')
# # Q = plt.quiver(X, Y, u, v, units='width')
# # qk = plt.quiverkey(Q, 0.9, 0.9, 2, r'$2 \frac{m}{s}$', labelpos='E',
# #                    coordinates='figure')
#
# # choose the 1st algorithm to get the convergence
#
#
#
#
# J=[]
# K=[]
# for i in range(max_iters):
#     current_x1 = next_x1
#     current_x2 = next_x2
#     next_x1 = current_x1 - gamma * df1(current_x1)
#     next_x2 = current_x2 - gamma * df2(current_x2)
#     J=np.append(J,current_x1)
#     K=np.append(K,current_x2)
#     step1 = next_x1 - current_x1
#     step2 = next_x2 - current_x1
#     count += 1
#     if abs(step1) <= precision and abs(step2) <= precision:
#         break
#
# plt.plot(J,K)
# print("Minimum at", next_x1, next_x2)
# print(str(count) +" steps")
#
# plt.show()
#
# next_x1 = 1  # We start the search at x=6
# next_x2 = 3
# gamma = 0.002  # Step size multiplier
# precision = 0.00001  # Desired precision of result
# max_iters = 100000  # Maximum number of iterations
#
# # Derivative function
# df1 = lambda x1: 2*x1
# df2 = lambda x2: 2*x2
# count = 0
# # fig_3 = plt.figure()
x1_list=[]
f_list=[]
#
#
# plt.plot(x1_list, f_list)
#
#
# ## Q2.5.1
#
# M=[]
# N=[]
#
# for i in range(max_iters):
#     current_x1 = next_x1
#     current_x2 = next_x2
#     next_x1 = current_x1 - gamma * df1(current_x1)
#     next_x2 = current_x2 - gamma * df2(current_x2)
#     step1 = next_x1 - current_x1
#     step2 = next_x2 - current_x1
#     count += 1
#
#     f = (2*current_x1)**2 + (2*current_x2)**2
#     x1_list.append(next_x1)
#     f_list.append(f)
#     M = np.append(M, i)
#     # N = np.append(N,f_list)
#     if abs(step1) <= precision and abs(step2) <= precision:
#         break
#
#
# plt.plot(M, f_list)
# plt.show()
#
# print("Minimum at", next_x1, next_x2)
# print(str(count) +" steps")

# Q2.5.2
x1_list=[]
f_list=[]
x2_list=[]

for i in range(max_iters):
    current_x1 = next_x1
    current_x2 = next_x2
    next_x1 = current_x1 - gamma * df1(current_x1)
    next_x2 = current_x2 - gamma * df2(current_x2)
    step1 = next_x1 - current_x1
    step2 = next_x2 - current_x1
    count += 1

    f = (2*current_x1)**2 + (2*current_x2)**2
    x1_list.append(next_x1)
    f_list.append(f)
    x2_list.append(next_x2)

    if abs(step1) <= precision and abs(step2) <= precision:
        break

d_x1_list = []
d_x2_list = []
d_x1 = 0
d_x2 = 0
cnt=0
for i in range(count):
    d_x1 = abs(x1_list[i] - next_x1)
    d_x2 = abs(x2_list[i] - next_x2)
    d_x1_list = np.append(d_x1_list,(d_x1**2+d_x2**2)**0.5)
    # d_x2_list = np.append(d_x2_list,d_x2)
    cnt=cnt+1
    d_x2_list = np.append(d_x2_list, cnt)


plt.plot(d_x2_list,d_x1_list)
plt.show()

print("Minimum at", next_x1, next_x2)
print(str(count) +" steps")

'''
    Question 3.1
'''
#import numpy as np
#import cvxpy as cp

#def water_filling(n, a, sum_x=1):
#    '''
#    Boyd and Vandenberghe, Convex Optimization, example 5.2 page 145
#    Water-filling.
#
#    This problem arises in information theory, in allocating power to a set of
#    n communication channels in order to maximise the total channel capacity.
#    The variable x_i represents the transmitter power allocated to the ith channel,
#    and log(α_i+x_i) gives the capacity or maximum communication rate of the channel.
#    The objective is to minimise -∑log(α_i+x_i) subject to the constraint ∑x_i = 1
#    '''
#
#    # Declare variables and parameters
#    x = cp.Variable(n)
##    alpha = cp.Parameter(n, nonneg=True)
#    alpha = cp.Parameter(n, sign='positive')
#    alpha.value = a
#
#    # Choose objective function. Interpret as maximising the total communication rate of all the channels
#    obj = cp.Maximize(cp.sum_entries(cp.log(alpha + x)))
#
#    # Declare constraints
#    constraints = [x >= 0, cp.sum_entries(x) - sum_x == 0]
#
#    # Solve
#    prob = cp.Problem(obj, constraints)
#    prob.solve()
#    if(prob.status=='optimal'):
#        return prob.status, prob.value, x.value, constraints
#    else:
#        return prob.status, np.nan, np.nan
#
# # As an example, we will solve the water filling problem with 3 buckets, each with different α
#np.set_printoptions(precision=3)
#buckets = 8
#alpha = np.array([0.8, 1.0, 1.2, 0.2, 0.6, 0.1, 0.2, 0.5])
#
#stat, prob, x, constraints = water_filling(buckets, alpha)
##x = x.flatten()
#
#print('Problem status: {}'.format(stat))
#print('Optimal communication rate = {:.4g} '.format(prob))
#print('Transmitter powers:\n{}'.format(x))
#print('Lagrange multiplier:\n{}'.format(constraints[0].dual_value))

#import matplotlib
#import matplotlib.pylab as plt
##%matplotlib inline
#
#matplotlib.rcParams.update({'font.size': 14})
#
#axis = np.arange(0.5,buckets+1.5,1)
#index = axis+0.5
#X = x.copy()
#X = X.T
#Y = alpha + X
#
## to include the last data point as a step,






